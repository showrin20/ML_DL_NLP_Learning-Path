{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPC+jFPcuhL8ACN/JoNZvNM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/showrin20/Machine-Learning-Learning-Path/blob/main/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfMCa7kUxyA1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff88647d-3cd2-48b0-ae9c-e5844fa29d65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Validation Error: 0.0062\n",
            "Epoch 2: Validation Error: 0.0062\n",
            "Early stopping at epoch 2 as no improvement in validation accuracy.\n",
            "Training Accuracy: 0.9996923076923077, Precision: 1.0, Recall: 0.9993612264452252\n",
            "Validation Accuracy: 0.9938423645320197, Precision: 1.0, Recall: 0.9874055415617129\n",
            "Test Accuracy: 0.9987684729064039, Precision: 1.0, Recall: 0.9974226804123711\n",
            "Most indicative of poisonous: ['odor_foul' 'odor_creosote' 'spore-print-color_green']\n",
            "Most indicative of edible: ['odor_none' 'odor_almond' 'odor_anise']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "def read_data(filename):\n",
        "    #reads in a csv and sements the data\n",
        "    #randomizes the order of the data, then splits it into different sets\n",
        "    #returns separate inputs (x) and outputs (y) for each of training, test, and validation\n",
        "    #also returns a list of column names, which may be useful for determining heavily weighted features\n",
        "    df = pd.read_csv(filename)\n",
        "    data = df.to_numpy()\n",
        "    np.random.shuffle(data)\n",
        "    test_size = int(data.shape[0]/10)\n",
        "    data_test = data[:test_size]\n",
        "    data_val = data[test_size:2*test_size]\n",
        "    data_train = data[2*test_size:]\n",
        "    x_train = data_train[:,1:]\n",
        "    y_train = data_train[:,0]\n",
        "    x_val = data_val[:,1:]\n",
        "    y_val = data_val[:,0]\n",
        "    x_test = data_test[:,1:]\n",
        "    y_test = data_test[:,0]\n",
        "    return x_train, y_train, x_val, y_val, x_test, y_test, df.columns.values\n",
        "\n",
        "\n",
        "def add_ones(x):\n",
        "    #takes an array of feature vectors and adds a column of 1s to the start\n",
        "    #useful for logistic regression, since x_0 is always 1\n",
        "    return np.insert(x, 0, np.ones(x.shape[0]), axis = 1)\n",
        "\n",
        "def compute_hypothesis(x, weights):\n",
        "    #computes the hypothesis function for logistic function given data x and weights\n",
        "    #if x is a single feature vector, will return a scalar\n",
        "    #if x is a matrix of feature vectors, will return a vector containing the hypothesis for each row\n",
        "    prod = x.dot(weights)\n",
        "    return 1/(1 + np.exp(-prod))\n",
        "\n",
        "def rank_features(weights, feats):\n",
        "    #takes in a weight vector and an array of feature names\n",
        "    #returns a sorted array of features, sorted from most negatively weighted to most positively weighted\n",
        "    #note that feats MUST be a numpy array of the same length as weights\n",
        "    #if feats[i] does not correspond to weights[i], this will not return accurate results\n",
        "    imp = np.argsort(weights)\n",
        "    return feats[imp]\n",
        "def perceptron(x_train, y_train, x_val, y_val, learning_rate=0.01, epochs=1000):\n",
        "    weights = np.zeros(x_train.shape[1])\n",
        "    bias = 0\n",
        "    best_validation_accuracy = 0\n",
        "    for epoch in range(epochs):\n",
        "        for x, y in zip(x_train, y_train):\n",
        "            linear_output = np.dot(x, weights) + bias\n",
        "            predicted_result = 1 if linear_output > 0 else -1\n",
        "            if y != predicted_result:\n",
        "                update = learning_rate * (y - predicted_result)\n",
        "                weights += update * x\n",
        "                bias += update\n",
        "\n",
        "        val_predicted_results = np.dot(x_val, weights) + bias\n",
        "        val_predicted_results = np.where(val_predicted_results > 0, 1, -1)\n",
        "        validation_accuracy = accuracy_score(y_val, val_predicted_results)\n",
        "\n",
        "        validation_error = 1 - validation_accuracy\n",
        "        print(f\"Epoch {epoch+1}: Validation Error: {validation_error:.4f}\")\n",
        "\n",
        "        if validation_accuracy <= best_validation_accuracy:\n",
        "            print(f\"Early stopping at epoch {epoch+1} as no improvement in validation accuracy.\")\n",
        "            break\n",
        "        best_validation_accuracy = validation_accuracy\n",
        "    return weights, bias\n",
        "\n",
        "\n",
        "def evaluate_performance(x, y, weights, bias):\n",
        "    predicted_results = np.dot(x, weights) + bias\n",
        "    predicted_results = np.where(predicted_results > 0, 1, -1)\n",
        "    accuracy = accuracy_score(y, predicted_results)\n",
        "    precision = precision_score(y, predicted_results, pos_label=1)\n",
        "    recall = recall_score(y, predicted_results, pos_label=1)\n",
        "    return accuracy, precision, recall\n",
        "\n",
        "filename = 'mushrooms_perceptron.csv'\n",
        "x_train, y_train, x_val, y_val, x_test, y_test, feature_names = read_data(filename)\n",
        "\n",
        "weights, bias = perceptron(x_train, y_train, x_val, y_val)\n",
        "\n",
        "training_accuracy, training_precision, train_recall = evaluate_performance(x_train, y_train, weights, bias)\n",
        "validation_accuracy, validation_precision, validation_recall = evaluate_performance(x_val, y_val, weights, bias)\n",
        "test_accuracy, test_precision, test_recall = evaluate_performance(x_test, y_test, weights, bias)\n",
        "\n",
        "print(f\"Training Accuracy: {training_accuracy}, Precision: {training_precision}, Recall: {train_recall}\")\n",
        "print(f\"Validation Accuracy: {validation_accuracy}, Precision: {validation_precision}, Recall: {validation_recall}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}\")\n",
        "\n",
        "\n",
        "ranked_features = rank_features(weights, feature_names[1:])\n",
        "print(f\"Most indicative of poisonous: {ranked_features[-3:]}\")\n",
        "print(f\"Most indicative of edible: {ranked_features[:3]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BbwMz4IUeVpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_regression_sgd(x_train, y_train, learning_rate=0.01, epochs=1000):\n",
        "    x_train = add_ones(x_train)\n",
        "    weights = np.zeros(x_train.shape[1])\n",
        "    for epoch in range(epochs):\n",
        "        for x, y in zip(x_train, y_train):\n",
        "            predicted_result = compute_hypothesis(x, weights)\n",
        "            error = y - predicted_result\n",
        "            weights += learning_rate * error * x\n",
        "    return weights\n",
        "\n",
        "\n",
        "def evaluate_performance_logistic(x, y, weights):\n",
        "    x = add_ones(x)\n",
        "    predicted_results = compute_hypothesis(x, weights)\n",
        "    predicted_results = np.where(predicted_results >= 0.5, 1, 0)\n",
        "    accuracy = accuracy_score(y, predicted_results)\n",
        "    precision = precision_score(y, predicted_results)\n",
        "    recall = recall_score(y, predicted_results)\n",
        "    return accuracy, precision, recall\n",
        "\n",
        "filename1 = 'mushrooms_logistic.csv'\n",
        "x_train, y_train, x_val, y_val, x_test, y_test, feature_names = read_data(filename1)\n",
        "\n",
        "weights = logistic_regression_sgd(x_train, y_train)\n",
        "\n",
        "train_metrics = evaluate_performance_logistic(x_train, y_train, weights)\n",
        "val_metrics = evaluate_performance_logistic(x_val, y_val, weights)\n",
        "test_metrics = evaluate_performance_logistic(x_test, y_test, weights)\n",
        "\n",
        "print(\"Training Metrics (Accuracy, Precision, Recall):\", train_metrics)\n",
        "print(\"Validation Metrics (Accuracy, Precision, Recall):\", val_metrics)\n",
        "print(\"Test Metrics (Accuracy, Precision, Recall):\", test_metrics)\n",
        "\n",
        "ranked_features = rank_features(weights[1:], feature_names[1:])\n",
        "print(\"Features most indicative of being poisonous:\", ranked_features[-3:])\n",
        "print(\"Features most indicative of being edible:\", ranked_features[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Nbx1q-Btpub",
        "outputId": "1a9d76b9-066b-42d5-b1dc-a20f49647741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Metrics (Accuracy, Precision, Recall): (1.0, 1.0, 1.0)\n",
            "Validation Metrics (Accuracy, Precision, Recall): (1.0, 1.0, 1.0)\n",
            "Test Metrics (Accuracy, Precision, Recall): (1.0, 1.0, 1.0)\n",
            "Features most indicative of being poisonous: ['odor_foul' 'odor_creosote' 'spore-print-color_green']\n",
            "Features most indicative of being edible: ['odor_none' 'odor_almond' 'odor_anise']\n"
          ]
        }
      ]
    }
  ]
}
